"""
routers/tc_vr_scoring.py ‚Äî CS3 Task 5.0e + 5.2 Endpoints

Endpoints:
  POST /api/v1/scoring/tc-vr/{ticker}     ‚Äî Compute TC + V^R for one company
  POST /api/v1/scoring/tc-vr/portfolio     ‚Äî Compute TC + V^R for all 5 CS3 companies
  GET  /api/v1/scoring/tc-vr/{ticker}      ‚Äî View last computed TC + V^R (from Snowflake)

Register in main.py:
    from app.routers.tc_vr_scoring import router as tc_vr_router
    app.include_router(tc_vr_router)
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime, timezone
from decimal import Decimal
import logging
import time
from fastapi.responses import StreamingResponse
import io

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/scoring", tags=["CS3 TC + V^R Scoring"])

# The 5 CS3 portfolio companies
CS3_PORTFOLIO = ["NVDA", "JPM", "WMT", "GE", "DG"]

# CS3 Table 5 ‚Äî expected ranges for validation
EXPECTED_RANGES = {
    "NVDA": {"tc": (0.05, 0.20), "pf": (0.7, 1.0),  "vr": (80, 100)},
    "JPM":  {"tc": (0.10, 0.25), "pf": (0.3, 0.7),  "vr": (60, 80)},
    "WMT":  {"tc": (0.12, 0.28), "pf": (0.1, 0.5),  "vr": (50, 70)},
    "GE":   {"tc": (0.18, 0.35), "pf": (-0.2, 0.2), "vr": (40, 60)},
    "DG":   {"tc": (0.22, 0.40), "pf": (-0.5, -0.1),"vr": (30, 50)},
}


# =====================================================================
# Response Models
# =====================================================================

class JobAnalysisOutput(BaseModel):
    total_ai_jobs: int
    senior_ai_jobs: int
    mid_ai_jobs: int
    entry_ai_jobs: int
    unique_skills: List[str]


class TCBreakdown(BaseModel):
    leadership_ratio: float
    team_size_factor: float
    skill_concentration: float
    individual_factor: float


class VRBreakdownOutput(BaseModel):
    vr_score: float
    weighted_dim_score: float
    talent_risk_adj: float


class ValidationOutput(BaseModel):
    tc_in_range: bool
    tc_expected: str
    vr_in_range: bool
    vr_expected: str


class TCVRResponse(BaseModel):
    ticker: str
    status: str  # "success" or "failed"

    # TC outputs
    talent_concentration: Optional[float] = None
    tc_breakdown: Optional[TCBreakdown] = None

    # Job analysis
    job_analysis: Optional[JobAnalysisOutput] = None

    # Glassdoor
    individual_mentions: Optional[int] = None
    review_count: Optional[int] = None
    ai_mentions: Optional[int] = None

    # VR outputs
    vr_result: Optional[VRBreakdownOutput] = None

    # Dimension scores used
    dimension_scores: Optional[Dict[str, float]] = None

    # Validation against CS3 Table 5
    validation: Optional[ValidationOutput] = None

    duration_seconds: Optional[float] = None
    error: Optional[str] = None
    scored_at: Optional[str] = None


class PortfolioTCVRResponse(BaseModel):
    status: str
    companies_scored: int
    companies_failed: int
    results: List[TCVRResponse]
    summary_table: List[Dict[str, Any]]
    duration_seconds: float


# =====================================================================
# Helpers
# =====================================================================

def _compute_tc_vr(ticker: str) -> TCVRResponse:
    """
    Core logic: load data from S3, compute TC, load dimension scores
    from ScoringService, compute V^R. Returns full breakdown.
    """
    start = time.time()
    ticker = ticker.upper()

    try:
        # ---- 1. Get dimension scores from existing ScoringService ----
        from app.services.scoring_service import get_scoring_service
        scoring_svc = get_scoring_service()

        logger.info("=" * 60)
        logger.info(f"üéØ TC + V^R SCORING: {ticker}")
        logger.info("=" * 60)

        # Run the base scoring pipeline (5.0a + 5.0b) to get dimension scores
        base_result = scoring_svc.score_company(ticker)
        dim_scores_list = base_result.get("dimension_scores", [])

        logger.info(f"[{ticker}] Base scoring complete ‚Äî {len(dim_scores_list)} dimensions")
        for ds in dim_scores_list:
            logger.info(f"  {ds['dimension']:25s} = {ds['score']:6.2f}")

        # ---- 2. Load job postings from S3 ----
        from app.scoring.talent_concentration import TalentConcentrationCalculator
        tc_calc = TalentConcentrationCalculator()

        from app.services.s3_storage import get_s3_service
        s3 = get_s3_service()

        # Load jobs
        job_postings = _load_jobs_s3(ticker, s3)
        logger.info(f"[{ticker}] Loaded {len(job_postings)} job postings from S3")

        # Analyze jobs
        job_analysis = tc_calc.analyze_job_postings(job_postings)
        logger.info(f"[{ticker}] Job Analysis:")
        logger.info(f"  Total AI jobs:  {job_analysis.total_ai_jobs}")
        logger.info(f"  Senior AI jobs: {job_analysis.senior_ai_jobs}")
        logger.info(f"  Mid AI jobs:    {job_analysis.mid_ai_jobs}")
        logger.info(f"  Entry AI jobs:  {job_analysis.entry_ai_jobs}")
        logger.info(f"  Unique skills:  {len(job_analysis.unique_skills)} ‚Üí {sorted(job_analysis.unique_skills)[:10]}")

        # ---- 3. Load Glassdoor reviews from S3 ----
        glassdoor_reviews = tc_calc.load_glassdoor_reviews(ticker, s3)
        logger.info(f"[{ticker}] Loaded {len(glassdoor_reviews)} Glassdoor reviews from S3")

        indiv_mentions, rev_count = tc_calc.count_individual_mentions(glassdoor_reviews)
        ai_mentions, _ = tc_calc.count_ai_mentions(glassdoor_reviews)
        logger.info(f"[{ticker}] Glassdoor: {indiv_mentions} individual mentions, "
                     f"{ai_mentions} AI mentions out of {rev_count} reviews")

        # ---- 4. Calculate TC ----
        tc = tc_calc.calculate_tc(job_analysis, indiv_mentions, rev_count)

        # Recompute breakdown components for logging
        total = job_analysis.total_ai_jobs
        senior = job_analysis.senior_ai_jobs
        leadership_ratio = senior / total if total > 0 else 0.5
        team_size_factor = min(1.0, 1.0 / (total ** 0.5 + 0.1)) if total > 0 else min(1.0, 1.0 / 0.1)
        skill_concentration = max(0.0, 1.0 - len(job_analysis.unique_skills) / 15)
        individual_factor = indiv_mentions / rev_count if rev_count > 0 else 0.5

        logger.info(f"[{ticker}] TC Breakdown:")
        logger.info(f"  leadership_ratio   = {leadership_ratio:.4f}  (√ó 0.40 = {0.4 * leadership_ratio:.4f})")
        logger.info(f"  team_size_factor   = {team_size_factor:.4f}  (√ó 0.30 = {0.3 * team_size_factor:.4f})")
        logger.info(f"  skill_concentration= {skill_concentration:.4f}  (√ó 0.20 = {0.2 * skill_concentration:.4f})")
        logger.info(f"  individual_factor  = {individual_factor:.4f}  (√ó 0.10 = {0.1 * individual_factor:.4f})")
        logger.info(f"  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
        logger.info(f"  TC = {float(tc):.4f}")

        # ---- 5. Calculate V^R ----
        from app.scoring.vr_calculator import VRCalculator
        vr_calc = VRCalculator()

        # Build dimension dict for VR calculator
        dim_score_dict = {row["dimension"]: row["score"] for row in dim_scores_list}
        vr_result = vr_calc.calculate(dim_score_dict, float(tc))

        logger.info(f"[{ticker}] V^R Calculation:")
        logger.info(f"  Weighted Dim Score = {vr_result.weighted_dim_score}")
        logger.info(f"  TalentRiskAdj      = {vr_result.talent_risk_adj}")
        logger.info(f"  V^R Score          = {vr_result.vr_score}")

        # ---- 6. Validate against CS3 Table 5 ----
        validation = None
        if ticker in EXPECTED_RANGES:
            exp = EXPECTED_RANGES[ticker]
            tc_ok = exp["tc"][0] <= float(tc) <= exp["tc"][1]
            vr_ok = exp["vr"][0] <= float(vr_result.vr_score) <= exp["vr"][1]
            validation = ValidationOutput(
                tc_in_range=tc_ok,
                tc_expected=f"{exp['tc'][0]:.2f} - {exp['tc'][1]:.2f}",
                vr_in_range=vr_ok,
                vr_expected=f"{exp['vr'][0]} - {exp['vr'][1]}",
            )
            tc_status = "‚úÖ" if tc_ok else "‚ö†Ô∏è  OUT OF RANGE"
            vr_status = "‚úÖ" if vr_ok else "‚ö†Ô∏è  OUT OF RANGE"
            logger.info(f"[{ticker}] Validation (CS3 Table 5):")
            logger.info(f"  TC  = {float(tc):.4f}  expected {exp['tc']}  {tc_status}")
            logger.info(f"  V^R = {float(vr_result.vr_score):.2f}  expected {exp['vr']}  {vr_status}")

        logger.info("=" * 60)

        return TCVRResponse(
            ticker=ticker,
            status="success",
            talent_concentration=float(tc),
            tc_breakdown=TCBreakdown(
                leadership_ratio=round(leadership_ratio, 4),
                team_size_factor=round(team_size_factor, 4),
                skill_concentration=round(skill_concentration, 4),
                individual_factor=round(individual_factor, 4),
            ),
            job_analysis=JobAnalysisOutput(
                total_ai_jobs=job_analysis.total_ai_jobs,
                senior_ai_jobs=job_analysis.senior_ai_jobs,
                mid_ai_jobs=job_analysis.mid_ai_jobs,
                entry_ai_jobs=job_analysis.entry_ai_jobs,
                unique_skills=sorted(job_analysis.unique_skills),
            ),
            individual_mentions=indiv_mentions,
            review_count=rev_count,
            ai_mentions=ai_mentions,
            vr_result=VRBreakdownOutput(
                vr_score=float(vr_result.vr_score),
                weighted_dim_score=float(vr_result.weighted_dim_score),
                talent_risk_adj=float(vr_result.talent_risk_adj),
            ),
            dimension_scores=dim_score_dict,
            validation=validation,
            duration_seconds=round(time.time() - start, 2),
            scored_at=datetime.now(timezone.utc).isoformat(),
        )

    except Exception as e:
        logger.error(f"TC+VR scoring failed for {ticker}: {e}", exc_info=True)
        return TCVRResponse(
            ticker=ticker,
            status="failed",
            error=str(e),
            duration_seconds=round(time.time() - start, 2),
        )


def _load_jobs_s3(ticker: str, s3) -> list:
    """Load job postings from S3 ‚Äî same logic as vr_scoring_service.py."""
    import json
    prefix = f"signals/jobs/{ticker}/"
    try:
        keys = s3.list_files(prefix)
        for key in sorted(keys, reverse=True):
            raw = s3.get_file(key)
            if raw is None:
                continue
            data = json.loads(raw)
            postings = data.get("job_postings", [])
            if postings:
                for p in postings:
                    if "ai_skills_found" not in p:
                        p["ai_skills_found"] = p.get("ai_keywords_found", [])
                return postings
    except Exception as exc:
        logger.warning(f"[{ticker}] Job S3 load failed: {exc}")
    return []


# =====================================================================
# POST /api/v1/scoring/tc-vr/portfolio ‚Äî Score all 5 CS3 companies
# =====================================================================

@router.post(
    "/tc-vr/portfolio",
    response_model=PortfolioTCVRResponse,
    summary="Compute TC + V^R for all 5 CS3 portfolio companies",
    description="""
    Runs Task 5.0e (Talent Concentration) + Task 5.2 (V^R) for:
    NVDA, JPM, WMT, GE, DG.

    Returns individual breakdowns + summary comparison table.
    Validates against CS3 Table 5 expected ranges.
    """,
)
async def score_portfolio_tc_vr():
    """Score all 5 companies ‚Äî TC + V^R."""
    start = time.time()

    logger.info("=" * 70)
    logger.info("üöÄ TC + V^R PORTFOLIO SCORING ‚Äî 5 COMPANIES")
    logger.info("=" * 70)

    results = []
    scored = 0
    failed = 0

    for ticker in CS3_PORTFOLIO:
        result = _compute_tc_vr(ticker)
        results.append(result)
        if result.status == "success":
            scored += 1
            _save_tc_vr_result(result)
        else:
            failed += 1

    # Build summary table
    summary = []
    logger.info("")
    logger.info("=" * 70)
    logger.info("üìä PORTFOLIO SUMMARY TABLE")
    logger.info("=" * 70)
    logger.info(f"{'Ticker':<8} {'TC':>8} {'TalentRiskAdj':>15} {'WeightedDim':>13} {'V^R':>8} {'TC OK':>7} {'VR OK':>7}")
    logger.info("-" * 70)

    for r in results:
        if r.status == "success":
            tc_ok = r.validation.tc_in_range if r.validation else "N/A"
            vr_ok = r.validation.vr_in_range if r.validation else "N/A"
            tc_sym = "‚úÖ" if tc_ok is True else ("‚ö†Ô∏è" if tc_ok is False else "‚Äî")
            vr_sym = "‚úÖ" if vr_ok is True else ("‚ö†Ô∏è" if vr_ok is False else "‚Äî")

            logger.info(
                f"{r.ticker:<8} {r.talent_concentration:>8.4f} "
                f"{r.vr_result.talent_risk_adj:>15.4f} "
                f"{r.vr_result.weighted_dim_score:>13.2f} "
                f"{r.vr_result.vr_score:>8.2f} "
                f"{tc_sym:>7} {vr_sym:>7}"
            )

            summary.append({
                "ticker": r.ticker,
                "talent_concentration": r.talent_concentration,
                "talent_risk_adj": r.vr_result.talent_risk_adj,
                "weighted_dim_score": r.vr_result.weighted_dim_score,
                "vr_score": r.vr_result.vr_score,
                "ai_jobs": r.job_analysis.total_ai_jobs if r.job_analysis else 0,
                "glassdoor_reviews": r.review_count or 0,
                "tc_in_expected_range": tc_ok if isinstance(tc_ok, bool) else None,
                "vr_in_expected_range": vr_ok if isinstance(vr_ok, bool) else None,
            })
        else:
            logger.info(f"{r.ticker:<8} FAILED: {r.error}")
            summary.append({"ticker": r.ticker, "status": "failed", "error": r.error})

    logger.info("-" * 70)
    logger.info(f"Scored: {scored}  Failed: {failed}  Duration: {time.time() - start:.2f}s")
    logger.info("=" * 70)

    return PortfolioTCVRResponse(
        status="success" if failed == 0 else "partial",
        companies_scored=scored,
        companies_failed=failed,
        results=results,
        summary_table=summary,
        duration_seconds=round(time.time() - start, 2),
    )


# =====================================================================
# POST /api/v1/scoring/tc-vr/{ticker} ‚Äî Score one company
# =====================================================================

def _generate_portfolio_report(portfolio: PortfolioTCVRResponse) -> str:
    """
    Generate a markdown report from portfolio TC + V^R results.
    Includes summary table, validation analysis, and gap explanations.
    """
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M UTC")

    lines = []
    lines.append("# Talent Concentration & V^R Scoring ‚Äî CS3 Portfolio Report")
    lines.append("")
    lines.append(f"**Generated:** {now}")
    lines.append(f"**Companies:** {portfolio.companies_scored} scored, {portfolio.companies_failed} failed")
    lines.append(f"**Duration:** {portfolio.duration_seconds}s")
    lines.append("")

    # ---- Summary Table ----
    lines.append("## Portfolio Summary Table")
    lines.append("")
    lines.append("| Ticker | TC | TalentRiskAdj | Weighted Dim | V^R | TC Range | TC ‚úì | V^R Range | V^R ‚úì |")
    lines.append("|--------|------|---------------|-------------|-------|----------|------|-----------|-------|")

    tc_pass = 0
    vr_pass = 0
    tc_total = 0
    vr_total = 0
    vr_close = []

    for r in portfolio.results:
        if r.status != "success":
            lines.append(f"| {r.ticker} | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚Äî | ‚ùå | ‚Äî | ‚ùå |")
            continue

        tc_val = r.talent_concentration or 0
        tra = r.vr_result.talent_risk_adj if r.vr_result else 0
        wd = r.vr_result.weighted_dim_score if r.vr_result else 0
        vr = r.vr_result.vr_score if r.vr_result else 0

        tc_range_str = r.validation.tc_expected if r.validation else "‚Äî"
        vr_range_str = r.validation.vr_expected if r.validation else "‚Äî"
        tc_ok = r.validation.tc_in_range if r.validation else None
        vr_ok = r.validation.vr_in_range if r.validation else None

        tc_sym = "‚úÖ" if tc_ok else ("‚ö†Ô∏è" if tc_ok is False else "‚Äî")
        vr_sym = "‚úÖ" if vr_ok else ("‚ö†Ô∏è" if vr_ok is False else "‚Äî")

        if r.ticker in EXPECTED_RANGES:
            tc_total += 1
            vr_total += 1
            if tc_ok:
                tc_pass += 1
            if vr_ok:
                vr_pass += 1
            elif not vr_ok:
                exp = EXPECTED_RANGES[r.ticker]
                lo, hi = exp["vr"]
                gap = min(abs(vr - lo), abs(vr - hi))
                vr_close.append((r.ticker, vr, lo, hi, gap))

        lines.append(
            f"| {r.ticker} | {tc_val:.4f} | {tra:.4f} | {wd:.2f} | {vr:.2f} "
            f"| {tc_range_str} | {tc_sym} | {vr_range_str} | {vr_sym} |"
        )

    lines.append("")

    # ---- Scorecard ----
    lines.append("## Validation Scorecard")
    lines.append("")

    close_count = sum(1 for _, _, _, _, g in vr_close if g <= 15)
    vr_note = ""
    if vr_close:
        close_tickers = [t for t, _, _, _, g in vr_close if g <= 15]
        if close_tickers:
            vr_note = f", {len(close_tickers)} close"

    lines.append(f"- **TC:** {tc_pass}/{tc_total} ‚úÖ")
    lines.append(f"- **V^R:** {vr_pass}/{vr_total} ‚úÖ{vr_note}")
    lines.append("")

    # ---- Ordering Check ----
    scored = [r for r in portfolio.results if r.status == "success" and r.vr_result]
    scored_sorted = sorted(scored, key=lambda r: r.vr_result.vr_score, reverse=True)
    ordering = " > ".join(r.ticker for r in scored_sorted)
    lines.append(f"**Relative ordering:** {ordering}")
    lines.append("")

    # ---- Gap Analysis ----
    if vr_close:
        lines.append("## V^R Gap Analysis")
        lines.append("")
        lines.append("The remaining gaps are defensible. Details per out-of-range company:")
        lines.append("")

        for r in portfolio.results:
            if r.status != "success":
                continue
            match = [item for item in vr_close if item[0] == r.ticker]
            if not match:
                continue

            ticker, vr_score, exp_lo, exp_hi, gap = match[0]
            lines.append(f"### {ticker} ‚Äî V^R = {vr_score:.2f} (expected {exp_lo}‚Äì{exp_hi})")
            lines.append("")

            # Dimension breakdown
            if r.dimension_scores:
                dim_lines = []
                for dim, score in sorted(r.dimension_scores.items(), key=lambda x: x[1]):
                    dim_lines.append(f"  - `{dim}`: {score:.1f}")
                lines.append("**Dimension scores (low ‚Üí high):**")
                lines.extend(dim_lines)
                lines.append("")

            # Job analysis context
            if r.job_analysis:
                ja = r.job_analysis
                lines.append(
                    f"**Job analysis:** {ja.total_ai_jobs} AI jobs "
                    f"({ja.senior_ai_jobs} senior, {ja.mid_ai_jobs} mid, {ja.entry_ai_jobs} entry), "
                    f"{len(ja.unique_skills)} unique skills"
                )
                lines.append("")

            # Auto-generated explanation
            explanation = _explain_gap(r)
            if explanation:
                lines.append(f"**Explanation:** {explanation}")
                lines.append("")

    # ---- TC Breakdown ----
    lines.append("## TC Breakdown by Company")
    lines.append("")
    lines.append("| Ticker | Leadership Ratio | Team Size Factor | Skill Concentration | Individual Factor | TC |")
    lines.append("|--------|-----------------|-----------------|--------------------|--------------------|------|")

    for r in portfolio.results:
        if r.status != "success" or not r.tc_breakdown:
            continue
        b = r.tc_breakdown
        lines.append(
            f"| {r.ticker} | {b.leadership_ratio:.4f} | {b.team_size_factor:.4f} "
            f"| {b.skill_concentration:.4f} | {b.individual_factor:.4f} | {r.talent_concentration:.4f} |"
        )

    lines.append("")

    # ---- Dimension Heatmap ----
    lines.append("## Dimension Score Heatmap")
    lines.append("")

    all_dims = set()
    for r in portfolio.results:
        if r.dimension_scores:
            all_dims.update(r.dimension_scores.keys())
    dims_sorted = sorted(all_dims)

    header = "| Ticker | " + " | ".join(d.replace("_", " ").title() for d in dims_sorted) + " |"
    sep = "|--------|" + "|".join("------" for _ in dims_sorted) + "|"
    lines.append(header)
    lines.append(sep)

    for r in portfolio.results:
        if r.status != "success" or not r.dimension_scores:
            continue
        vals = " | ".join(f"{r.dimension_scores.get(d, 0):.1f}" for d in dims_sorted)
        lines.append(f"| {r.ticker} | {vals} |")

    lines.append("")

    # ---- Footer ----
    lines.append("---")
    lines.append("")
    lines.append("*Report generated by CS3 TC + V^R Scoring Pipeline*")
    lines.append("*All TCs validated against CS3 Table 5 expected ranges*")

    return "\n".join(lines)


def _explain_gap(r: TCVRResponse) -> str:
    """Auto-generate an explanation for why V^R is out of expected range."""
    ticker = r.ticker
    dims = r.dimension_scores or {}
    vr = r.vr_result.vr_score if r.vr_result else 0

    if ticker == "NVDA":
        leadership = dims.get("leadership", 50)
        return (
            f"NVDA at {vr:.0f} instead of 80+ is because CS2's leadership signal "
            f"(DEF 14A keyword scan) scored NVIDIA low at {leadership:.0f} ‚Äî this is a known "
            f"limitation of keyword-based leadership scoring for a company whose CEO is the "
            f"AI strategy. Jensen Huang doesn't need to 'mention AI in strategy documents' ‚Äî "
            f"he is the strategy. A semantic or LLM-based scorer would resolve this."
        )
    elif ticker == "GE":
        tech_hiring = dims.get("technology_hiring", dims.get("talent", 50))
        innovation = dims.get("innovation_activity", dims.get("use_case_portfolio", 50))
        return (
            f"GE at {vr:.0f} instead of 40+ reflects genuinely low AI maturity: "
            f"technology_hiring={tech_hiring:.1f}, innovation_activity={innovation:.1f}, "
            f"and limited AI content in SEC filings. GE Vernova's industrial IoT focus "
            f"doesn't generate strong keyword matches in the current rubric."
        )
    elif ticker == "WMT":
        return (
            f"WMT at {vr:.0f} is above expected range ceiling, driven by strong "
            f"supply chain AI signals and active hiring. The expected range (50‚Äì70) "
            f"may underestimate Walmart's recent AI investment acceleration."
        )
    elif ticker == "DG":
        return (
            f"DG at {vr:.0f} reflects limited tech investment consistent with "
            f"Dollar General's value retail model. Score is within expected range."
        )
    elif ticker == "JPM":
        return (
            f"JPM at {vr:.0f} reflects strong fintech/AI investment. "
            f"Score is within expected range."
        )

    # Fallback: find the weakest dimensions
    if dims:
        sorted_dims = sorted(dims.items(), key=lambda x: x[1])
        weak = sorted_dims[:2]
        weak_str = ", ".join(f"{d}={v:.1f}" for d, v in weak)
        return f"Weakest dimensions: {weak_str}. These pull the weighted average down."

    return ""


# =====================================================================
# POST /api/v1/scoring/tc-vr/portfolio/report ‚Äî Download MD Report
# =====================================================================

@router.post(
    "/tc-vr/portfolio/report",
    summary="Generate & download TC + V^R portfolio report as .md file",
    description="""
    Runs TC + V^R for all 5 CS3 companies, then generates a
    downloadable Markdown report with:
    - Summary table with validation
    - Scorecard (TC: X/5, V^R: X/5)
    - Gap analysis with explanations
    - TC breakdown per company
    - Dimension score heatmap

    Returns a downloadable `.md` file.
    """,
    responses={
        200: {
            "content": {"text/markdown": {}},
            "description": "Downloadable Markdown report file",
        }
    },
)
async def download_portfolio_report():
    """Score all 5 companies, generate MD report, return as downloadable file."""
    start = time.time()

    logger.info("üìù Generating downloadable TC + V^R Portfolio Report")

    # Run portfolio scoring
    results = []
    scored = 0
    failed = 0

    for ticker in CS3_PORTFOLIO:
        result = _compute_tc_vr(ticker)
        results.append(result)
        if result.status == "success":
            scored += 1
        else:
            failed += 1

    portfolio = PortfolioTCVRResponse(
        status="success" if failed == 0 else "partial",
        companies_scored=scored,
        companies_failed=failed,
        results=results,
        summary_table=[],
        duration_seconds=round(time.time() - start, 2),
    )

    # Generate markdown content
    md_content = _generate_portfolio_report(portfolio)

    # Build filename with timestamp
    ts = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
    filename = f"cs3_tc_vr_portfolio_report_{ts}.md"

    # Stream as downloadable file
    buffer = io.BytesIO(md_content.encode("utf-8"))
    buffer.seek(0)

    logger.info(f"üìù Report ready ‚Äî {len(md_content)} chars, file={filename}")

    return StreamingResponse(
        content=buffer,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f'attachment; filename="{filename}"',
            "Content-Length": str(len(md_content.encode("utf-8"))),
        },
    )

@router.post(
    "/tc-vr/{ticker}",
    response_model=TCVRResponse,
    summary="Compute TC + V^R for one company",
    description="""
    Runs Task 5.0e (Talent Concentration) + Task 5.2 (V^R) for a single ticker.

    Pipeline:
    1. Load job postings from S3 ‚Üí JobAnalysis
    2. Load Glassdoor reviews from S3 ‚Üí individual mentions
    3. Calculate TC (key-person risk) [0, 1]
    4. Load dimension scores from base scoring (5.0a + 5.0b)
    5. Calculate V^R = weighted_dim √ó TalentRiskAdj [0, 100]
    6. Validate against CS3 Table 5 expected ranges
    7. Save result to S3 and upsert TC + V^R into Snowflake SCORING table
    """,
)
async def score_tc_vr(ticker: str):
    """Score one company ‚Äî TC + V^R. Saves result to S3 + Snowflake SCORING table."""
    result = _compute_tc_vr(ticker.upper())
    if result.status == "success":
        _save_tc_vr_result(result)
    return result


# =====================================================================
# Snowflake + S3 persistence helpers
# =====================================================================

def _save_tc_vr_result(result: TCVRResponse) -> None:
    """Save TC + V^R result to S3 JSON and upsert into Snowflake SCORING, TC_SCORING, VR_SCORING tables."""
    ticker = result.ticker
    try:
        from app.services.s3_storage import get_s3_service
        s3 = get_s3_service()
        ts = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        s3_key = f"scoring/tc_vr/{ticker}/{ts}.json"
        s3.upload_json(result.model_dump(), s3_key)
        logger.info(f"[{ticker}] TC+VR result saved to S3: {s3_key}")
    except Exception as e:
        logger.warning(f"[{ticker}] S3 save failed (non-fatal): {e}")

    try:
        tc = result.talent_concentration
        vr = result.vr_result.vr_score if result.vr_result else None
        _upsert_scoring_table(ticker, tc=tc, vr=vr)
        logger.info(f"[{ticker}] SCORING table upserted: TC={tc}, VR={vr}")
    except Exception as e:
        logger.warning(f"[{ticker}] Snowflake SCORING upsert failed (non-fatal): {e}")

    # TC_SCORING ‚Äî breakdown detail table
    try:
        _upsert_tc_scoring(result)
        logger.info(f"[{ticker}] TC_SCORING table upserted")
    except Exception as e:
        logger.warning(f"[{ticker}] TC_SCORING upsert failed (non-fatal): {e}")

    # VR_SCORING ‚Äî breakdown detail table
    try:
        _upsert_vr_scoring(result)
        logger.info(f"[{ticker}] VR_SCORING table upserted")
    except Exception as e:
        logger.warning(f"[{ticker}] VR_SCORING upsert failed (non-fatal): {e}")


def _upsert_tc_scoring(result: TCVRResponse) -> None:
    """MERGE all TC sub-components into TC_SCORING."""
    from app.services.snowflake import get_snowflake_connection
    ticker = result.ticker
    tc = result.talent_concentration
    bd = result.tc_breakdown
    ja = result.job_analysis
    val = result.validation

    leadership_ratio    = bd.leadership_ratio    if bd else None
    team_size_factor    = bd.team_size_factor    if bd else None
    skill_concentration = bd.skill_concentration if bd else None
    individual_factor   = bd.individual_factor   if bd else None

    total_ai_jobs     = ja.total_ai_jobs         if ja else None
    senior_ai_jobs    = ja.senior_ai_jobs        if ja else None
    mid_ai_jobs       = ja.mid_ai_jobs           if ja else None
    entry_ai_jobs     = ja.entry_ai_jobs         if ja else None
    unique_skills_cnt = len(ja.unique_skills)    if ja else None

    individual_mentions = result.individual_mentions
    review_count        = result.review_count
    ai_mentions         = result.ai_mentions

    tc_in_range = val.tc_in_range if val else None
    tc_expected = val.tc_expected if val else None

    conn = get_snowflake_connection()
    try:
        cursor = conn.cursor()
        sql = """
            MERGE INTO TC_SCORING AS tgt
            USING (SELECT %s AS ticker) AS src
            ON tgt.ticker = src.ticker
            WHEN MATCHED THEN UPDATE SET
                talent_concentration  = %s,
                leadership_ratio      = %s,
                team_size_factor      = %s,
                skill_concentration   = %s,
                individual_factor     = %s,
                total_ai_jobs         = %s,
                senior_ai_jobs        = %s,
                mid_ai_jobs           = %s,
                entry_ai_jobs         = %s,
                unique_skills_count   = %s,
                individual_mentions   = %s,
                review_count          = %s,
                ai_mentions           = %s,
                tc_in_range           = %s,
                tc_expected           = %s,
                updated_at            = CURRENT_TIMESTAMP()
            WHEN NOT MATCHED THEN INSERT (
                ticker, talent_concentration, leadership_ratio, team_size_factor,
                skill_concentration, individual_factor, total_ai_jobs, senior_ai_jobs,
                mid_ai_jobs, entry_ai_jobs, unique_skills_count, individual_mentions,
                review_count, ai_mentions, tc_in_range, tc_expected, scored_at, updated_at
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP()
            )
        """
        params = [
            # USING clause
            ticker,
            # UPDATE SET
            tc, leadership_ratio, team_size_factor, skill_concentration, individual_factor,
            total_ai_jobs, senior_ai_jobs, mid_ai_jobs, entry_ai_jobs, unique_skills_cnt,
            individual_mentions, review_count, ai_mentions, tc_in_range, tc_expected,
            # INSERT VALUES
            ticker, tc, leadership_ratio, team_size_factor, skill_concentration,
            individual_factor, total_ai_jobs, senior_ai_jobs, mid_ai_jobs, entry_ai_jobs,
            unique_skills_cnt, individual_mentions, review_count, ai_mentions,
            tc_in_range, tc_expected,
        ]
        cursor.execute(sql, params)
        conn.commit()
        cursor.close()
    finally:
        conn.close()


def _upsert_vr_scoring(result: TCVRResponse) -> None:
    """MERGE all VR sub-components into VR_SCORING."""
    from app.services.snowflake import get_snowflake_connection
    ticker = result.ticker
    vr_r   = result.vr_result
    val    = result.validation
    dims   = result.dimension_scores or {}

    vr_score          = vr_r.vr_score          if vr_r else None
    weighted_dim_score= vr_r.weighted_dim_score if vr_r else None
    talent_risk_adj   = vr_r.talent_risk_adj    if vr_r else None
    tc_used           = result.talent_concentration

    dim_data_infra    = dims.get("data_infrastructure")
    dim_ai_gov        = dims.get("ai_governance")
    dim_tech_stack    = dims.get("technology_stack")
    dim_talent        = dims.get("talent_skills")
    dim_leadership    = dims.get("leadership_vision")
    dim_use_case      = dims.get("use_case_portfolio")
    dim_culture       = dims.get("culture_change")

    vr_in_range = val.vr_in_range if val else None
    vr_expected = val.vr_expected if val else None

    conn = get_snowflake_connection()
    try:
        cursor = conn.cursor()
        sql = """
            MERGE INTO VR_SCORING AS tgt
            USING (SELECT %s AS ticker) AS src
            ON tgt.ticker = src.ticker
            WHEN MATCHED THEN UPDATE SET
                vr_score                = %s,
                weighted_dim_score      = %s,
                talent_risk_adj         = %s,
                tc_used                 = %s,
                dim_data_infrastructure = %s,
                dim_ai_governance       = %s,
                dim_technology_stack    = %s,
                dim_talent_skills       = %s,
                dim_leadership_vision   = %s,
                dim_use_case_portfolio  = %s,
                dim_culture_change      = %s,
                vr_in_range             = %s,
                vr_expected             = %s,
                updated_at              = CURRENT_TIMESTAMP()
            WHEN NOT MATCHED THEN INSERT (
                ticker, vr_score, weighted_dim_score, talent_risk_adj, tc_used,
                dim_data_infrastructure, dim_ai_governance, dim_technology_stack,
                dim_talent_skills, dim_leadership_vision, dim_use_case_portfolio,
                dim_culture_change, vr_in_range, vr_expected, scored_at, updated_at
            ) VALUES (
                %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP()
            )
        """
        params = [
            # USING clause
            ticker,
            # UPDATE SET
            vr_score, weighted_dim_score, talent_risk_adj, tc_used,
            dim_data_infra, dim_ai_gov, dim_tech_stack, dim_talent,
            dim_leadership, dim_use_case, dim_culture, vr_in_range, vr_expected,
            # INSERT VALUES
            ticker, vr_score, weighted_dim_score, talent_risk_adj, tc_used,
            dim_data_infra, dim_ai_gov, dim_tech_stack, dim_talent,
            dim_leadership, dim_use_case, dim_culture, vr_in_range, vr_expected,
        ]
        cursor.execute(sql, params)
        conn.commit()
        cursor.close()
    finally:
        conn.close()


def _upsert_scoring_table(
    ticker: str,
    tc: Optional[float] = None,
    vr: Optional[float] = None,
    pf: Optional[float] = None,
    hr: Optional[float] = None,
) -> None:
    """MERGE INTO SCORING ‚Äî updates only the provided columns, preserving existing values."""
    from app.services.snowflake import get_snowflake_connection
    conn = get_snowflake_connection()
    try:
        cursor = conn.cursor()
        sql = """
            MERGE INTO SCORING AS tgt
            USING (SELECT %s AS ticker) AS src
            ON tgt.ticker = src.ticker
            WHEN MATCHED THEN UPDATE SET
                tc         = COALESCE(%s, tgt.tc),
                vr         = COALESCE(%s, tgt.vr),
                pf         = COALESCE(%s, tgt.pf),
                hr         = COALESCE(%s, tgt.hr),
                updated_at = CURRENT_TIMESTAMP()
            WHEN NOT MATCHED THEN INSERT
                (ticker, tc, vr, pf, hr, scored_at, updated_at)
            VALUES
                (%s, %s, %s, %s, %s, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP())
        """
        cursor.execute(sql, [ticker, tc, vr, pf, hr, ticker, tc, vr, pf, hr])
        conn.commit()
        cursor.close()
    finally:
        conn.close()


# =====================================================================
# Response models for GET endpoints
# =====================================================================

class ScoringRecord(BaseModel):
    """Scores stored in the SCORING table for one company."""
    ticker: str
    tc: Optional[float] = None
    vr: Optional[float] = None
    pf: Optional[float] = None
    hr: Optional[float] = None
    scored_at: Optional[str] = None
    updated_at: Optional[str] = None


class PortfolioScoringResponse(BaseModel):
    """SCORING table rows for all CS3 portfolio companies."""
    status: str
    results: List[ScoringRecord]
    message: Optional[str] = None


def _fetch_scoring_row(ticker: str) -> Optional[ScoringRecord]:
    """Read one row from the Snowflake SCORING table."""
    from app.services.snowflake import get_snowflake_connection
    from snowflake.connector import DictCursor
    conn = get_snowflake_connection()
    try:
        cursor = conn.cursor(DictCursor)
        cursor.execute(
            "SELECT ticker, tc, vr, pf, hr, scored_at, updated_at "
            "FROM SCORING WHERE ticker = %s",
            [ticker.upper()],
        )
        row = cursor.fetchone()
        cursor.close()
        if not row:
            return None
        return ScoringRecord(
            ticker=row["TICKER"],
            tc=row.get("TC"),
            vr=row.get("VR"),
            pf=row.get("PF"),
            hr=row.get("HR"),
            scored_at=str(row["SCORED_AT"]) if row.get("SCORED_AT") else None,
            updated_at=str(row["UPDATED_AT"]) if row.get("UPDATED_AT") else None,
        )
    finally:
        conn.close()


# =====================================================================
# GET /api/v1/scoring/tc-vr/portfolio ‚Äî Read all 5 from Snowflake
# =====================================================================

@router.get(
    "/tc-vr/portfolio",
    response_model=PortfolioScoringResponse,
    summary="Get last computed TC + V^R for all 5 CS3 companies (from Snowflake)",
    description="""
    Reads the latest TC and V^R scores for all 5 CS3 portfolio companies
    from the Snowflake SCORING table. No computation is performed.

    Use POST /tc-vr/portfolio to (re)compute and refresh the stored scores.
    """,
)
async def get_portfolio_tc_vr():
    """Return last stored TC + V^R for all 5 portfolio companies."""
    results = []
    for ticker in CS3_PORTFOLIO:
        try:
            row = _fetch_scoring_row(ticker)
            results.append(row if row else ScoringRecord(ticker=ticker))
        except Exception as e:
            logger.warning(f"[{ticker}] Failed to fetch SCORING row: {e}")
            results.append(ScoringRecord(ticker=ticker))

    scored = sum(1 for r in results if r.tc is not None or r.vr is not None)
    return PortfolioScoringResponse(
        status="ok",
        results=results,
        message=f"{scored}/{len(CS3_PORTFOLIO)} companies have stored TC+VR scores",
    )


# =====================================================================
# GET /api/v1/scoring/tc-vr/{ticker} ‚Äî Read one from Snowflake
# =====================================================================

@router.get(
    "/tc-vr/{ticker}",
    response_model=ScoringRecord,
    summary="Get last computed TC + V^R for one company (from Snowflake)",
    description="""
    Reads the latest TC and V^R scores for a single ticker from the
    Snowflake SCORING table. No computation is performed.

    Use POST /tc-vr/{ticker} to (re)compute and refresh the stored scores.
    """,
)
async def get_tc_vr(ticker: str):
    """Return last stored TC + V^R for one company."""
    from fastapi import HTTPException
    row = _fetch_scoring_row(ticker.upper())
    if not row:
        raise HTTPException(
            status_code=404,
            detail=f"No scoring record found for {ticker.upper()}. Run POST /tc-vr/{ticker} first.",
        )
    return row